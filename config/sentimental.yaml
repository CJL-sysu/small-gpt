# data config
data_path: data/train.txt
sentimental_data_path: data/ChnSentiCorp_htl_all.csv
train_percent: 0.8
# model config
block_size: 256
vocab_size: 7587
n_layer: 26
n_head: 15
n_embd: 960
dropout: 0.05
bias: True
compile: True
# training config
max_epoch : 1919810
tensorboard_path :  ./tensorboard
device: cuda


train_batch: 24
test_batch: 8
grad_clip: 1.0
# learning rate
lr : 2e-4
warmup_steps: 1000
decay_steps: 100000
min_lr: 1e-5


# AdamW optimizer
weight_decay : 1e-1
beta1: 0.9
beta2: 0.95
# checkpoint config
checkpoint_root: ./checkpoints
save_freq: 4000 # save when global_step % save_freq == 0
base_model: checkpoints/old/1123-300M/cpt100000.pth
resume_from: NULL
# other config
seed :  114514
