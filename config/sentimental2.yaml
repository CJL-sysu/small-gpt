# data config
data_path: data/train.txt
sentimental_data_path: data/ChnSentiCorp_htl_all.csv
train_percent: 0.8
# model config
block_size: 256
vocab_size: 7587
n_layer: 26
n_head: 15
n_embd: 960
dropout: 0.05
bias: True
compile: True
use_mask: False
# training config
max_epoch : 20
tensorboard_path :  ./tensorboard/3
device: cuda
eval_freq: 100
frozen: False # 仅训练输出层和最后一个transformer块，冻结模型其余部分


train_batch: 24
test_batch: 8
grad_clip: 1.0
# learning rate
lr : 5e-5
warmup_steps: 100
decay_steps: 5000
min_lr: 6e-6


# AdamW optimizer
weight_decay : 1e-1
beta1: 0.9
beta2: 0.95
# checkpoint config
checkpoint_root: ./checkpoints
save_freq: 1919810 # save when global_step % save_freq == 0
base_model: checkpoints/pretrained/cpt300M.pth
resume_from: NULL
# other config
seed :  114514
